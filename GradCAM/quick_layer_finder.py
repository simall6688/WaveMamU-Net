# ä¿®å¤ç‰ˆå±‚åç§°è°ƒè¯•å·¥å…· - æ­£ç¡®å¤„ç†checkpointæ ¼å¼
import torch
import os


def debug_model_layers_fixed(model_path):
    """ä¿®å¤ç‰ˆï¼šæ­£ç¡®å¤„ç†checkpointä¸­çš„model_state_dict"""
    print("ğŸ” å¼€å§‹è¯¦ç»†åˆ†ææ¨¡å‹å±‚ç»“æ„...")
    print("=" * 80)

    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return None

    try:
        # åŠ è½½checkpoint
        print(f"ğŸ“ æ­£åœ¨åŠ è½½: {model_path}")
        checkpoint = torch.load(model_path, map_location='cpu',weights_only=False)
        print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹æ–‡ä»¶")

        # æ‰“å°checkpointçš„é”®
        print(f"\nğŸ“‹ CheckpointåŒ…å«çš„é”®: {list(checkpoint.keys())}")

        # ğŸ”§ å…³é”®ä¿®å¤ï¼šæ­£ç¡®è·å–æ¨¡å‹çš„state_dict
        if 'model_state_dict' in checkpoint:
            state_dict = checkpoint['model_state_dict']
            print("ğŸ”§ ä½¿ç”¨ checkpoint['model_state_dict'] âœ…")
        elif 'model' in checkpoint:
            state_dict = checkpoint['model']
            print("ğŸ”§ ä½¿ç”¨ checkpoint['model']")
        elif 'state_dict' in checkpoint:
            state_dict = checkpoint['state_dict']
            print("ğŸ”§ ä½¿ç”¨ checkpoint['state_dict']")
        else:
            # å¦‚æœéƒ½æ²¡æœ‰ï¼Œå¯èƒ½æ•´ä¸ªcheckpointå°±æ˜¯state_dict
            state_dict = checkpoint
            print("ğŸ”§ ç›´æ¥ä½¿ç”¨ checkpoint")

        # æ£€æŸ¥state_dictæ˜¯å¦åŒ…å«æ¨¡å‹å‚æ•°
        if not isinstance(state_dict, dict):
            print(f"âŒ state_dictä¸æ˜¯å­—å…¸ç±»å‹: {type(state_dict)}")
            return None

        # æ£€æŸ¥æ˜¯å¦åŒ…å«æƒé‡å‚æ•°
        param_names = list(state_dict.keys())
        weight_params = [name for name in param_names if '.weight' in name]

        if not weight_params:
            print(f"âŒ æ²¡æœ‰æ‰¾åˆ°.weightå‚æ•°ï¼Œå¯èƒ½state_dictæ ¼å¼ä¸æ­£ç¡®")
            print(f"ğŸ“‹ State_dictçš„å‰10ä¸ªé”®: {param_names[:10]}")
            return None

        print(f"ğŸ“Š State dictåŒ…å« {len(param_names)} ä¸ªå‚æ•°")
        print(f"âœ… æ‰¾åˆ° {len(weight_params)} ä¸ªæƒé‡å‚æ•°")

        # æ˜¾ç¤ºå‰20ä¸ªå‚æ•°åç§°
        print(f"\nğŸ“ å‰20ä¸ªå‚æ•°åç§°:")
        for i, name in enumerate(param_names[:20]):
            marker = "ğŸ”¥" if any(x in name.lower() for x in ['gdg', 'mamba', 'fusion', 'attn']) else "  "
            print(f"  {i + 1:2d}. {marker} {name}")

        if len(param_names) > 20:
            print(f"     ... è¿˜æœ‰ {len(param_names) - 20} ä¸ªå‚æ•°")

        # æå–å±‚åç§°ï¼ˆå»æ‰æƒé‡åç¼€ï¼‰
        print(f"\nğŸ—ï¸ æå–çš„å±‚ç»“æ„:")
        layer_names = set()

        for param_name in param_names:
            # ç§»é™¤å¸¸è§çš„å‚æ•°åç¼€
            layer_name = param_name
            suffixes = ['.weight', '.bias', '.running_mean', '.running_var',
                        '.num_batches_tracked', '.A_log', '.D']

            for suffix in suffixes:
                if layer_name.endswith(suffix):
                    layer_name = layer_name[:-len(suffix)]
                    break

            if layer_name and '.' in layer_name:  # åªè¦æœ‰å±‚æ¬¡ç»“æ„çš„
                layer_names.add(layer_name)

        # æ’åºå¹¶æ˜¾ç¤ºæ‰€æœ‰å±‚
        sorted_layers = sorted(layer_names)
        print(f"ğŸ“Š æ‰¾åˆ° {len(sorted_layers)} ä¸ªä¸åŒçš„å±‚:")

        for i, layer in enumerate(sorted_layers):
            # æ ‡è®°é‡è¦çš„åˆ›æ–°ç»„ä»¶
            marker = "  "
            if any(x in layer.lower() for x in ['gdg']):
                marker = "ğŸ”¥"
            elif any(x in layer.lower() for x in ['mamba', 'stage', 'mixer']):
                marker = "ğŸ"
            elif any(x in layer.lower() for x in ['fusion']):
                marker = "ğŸ”—"
            elif any(x in layer.lower() for x in ['esa', 'aca', 'attn']):
                marker = "ğŸ‘ï¸"

            print(f"  {i + 1:2d}. {marker} {layer}")

        # åˆ†æå±‚çš„æ¨¡å¼ - æ›´ç²¾ç¡®çš„åˆ†ç±»
        print(f"\nğŸ” åˆ›æ–°ç»„ä»¶å±‚åç§°åˆ†æ:")
        patterns = {
            'ğŸ”¥ GDGä¸‹é‡‡æ ·æ¨¡å—': [],
            'ğŸ Mambaç¼–ç å™¨': [],
            'ğŸ”— èåˆæ¨¡å—': [],
            'ğŸ‘ï¸ ESAç©ºé—´æ³¨æ„åŠ›': [],
            'ğŸ“Š ACAé€šé“æ³¨æ„åŠ›': [],
            'ğŸ¯ æ®‹å·®æ³¨æ„åŠ›': [],
            'ğŸ‘» Ghostæ¨¡å—': [],
            'â¬†ï¸ è§£ç å™¨æ¨¡å—': [],
            'ğŸ“¦ å…¶ä»–å·ç§¯å±‚': []
        }

        for layer in sorted_layers:
            categorized = False

            # GDGæ¨¡å— - æ ¸å¿ƒåˆ›æ–°ç‚¹1
            if any(x in layer.lower() for x in ['gdg']):
                patterns['ğŸ”¥ GDGä¸‹é‡‡æ ·æ¨¡å—'].append(layer)
                categorized = True

            # Mambaç›¸å…³ - æ ¸å¿ƒåˆ›æ–°ç‚¹2
            elif any(x in layer.lower() for x in ['mamba']):
                patterns['ğŸ Mambaç¼–ç å™¨'].append(layer)
                categorized = True

            # èåˆæ¨¡å— - æ ¸å¿ƒåˆ›æ–°ç‚¹3
            elif any(x in layer.lower() for x in ['fusion']):
                patterns['ğŸ”— èåˆæ¨¡å—'].append(layer)
                categorized = True

            # ESAç©ºé—´æ³¨æ„åŠ› - æ ¸å¿ƒåˆ›æ–°ç‚¹4
            elif any(x in layer.lower() for x in ['esa']):
                patterns['ğŸ‘ï¸ ESAç©ºé—´æ³¨æ„åŠ›'].append(layer)
                categorized = True

            # ACAé€šé“æ³¨æ„åŠ› - æ ¸å¿ƒåˆ›æ–°ç‚¹5
            elif any(x in layer.lower() for x in ['aca']):
                patterns['ğŸ“Š ACAé€šé“æ³¨æ„åŠ›'].append(layer)
                categorized = True

            # æ®‹å·®æ³¨æ„åŠ›
            elif any(x in layer.lower() for x in ['res_attn', 'sa']):
                patterns['ğŸ¯ æ®‹å·®æ³¨æ„åŠ›'].append(layer)
                categorized = True

            # Ghostæ¨¡å—
            elif any(x in layer.lower() for x in ['ghost']):
                patterns['ğŸ‘» Ghostæ¨¡å—'].append(layer)
                categorized = True

            # è§£ç å™¨
            elif any(x in layer.lower() for x in ['upconv', 'decoder']):
                patterns['â¬†ï¸ è§£ç å™¨æ¨¡å—'].append(layer)
                categorized = True

            # å…¶ä»–å·ç§¯
            elif 'conv' in layer.lower():
                patterns['ğŸ“¦ å…¶ä»–å·ç§¯å±‚'].append(layer)
                categorized = True

        # æ˜¾ç¤ºåˆ†ç±»ç»“æœ
        for category, layers in patterns.items():
            if layers:
                print(f"\n{category} ({len(layers)}ä¸ª):")
                for layer in layers:
                    print(f"   â€¢ {layer}")

        # ç”Ÿæˆè®ºæ–‡çº§åˆ«çš„GradCAMæ¨èå±‚
        print(f"\nğŸ¯ è®ºæ–‡çº§åˆ«GradCAMæ¨èå±‚:")
        recommended_layers = []

        # Figure 1: æ ¸å¿ƒåˆ›æ–°å¯¹æ¯”
        print(f"\nğŸ“Š Figure 1 - æ ¸å¿ƒåˆ›æ–°å¯¹æ¯”:")
        fig1_layers = []

        # GDGæ¨¡å—çš„æœ€ç»ˆå·ç§¯å±‚
        gdg_layers = patterns['ğŸ”¥ GDGä¸‹é‡‡æ ·æ¨¡å—']
        gdg_final = [l for l in gdg_layers if 'conv3_2' in l or l.endswith('conv2')]
        if gdg_final:
            fig1_layers.extend(gdg_final[:3])  # å‰3ä¸ªGDGå±‚
            print(f"   ğŸ”¥ GDGå±‚: {gdg_final[:3]}")

        # Mambaçš„å…³é”®é˜¶æ®µ
        mamba_layers = patterns['ğŸ Mambaç¼–ç å™¨']
        mamba_stages = [l for l in mamba_layers if 'stage' in l]
        if mamba_stages:
            fig1_layers.extend(mamba_stages[:2])  # å‰2ä¸ªMambaé˜¶æ®µ
            print(f"   ğŸ Mambaå±‚: {mamba_stages[:2]}")

        recommended_layers.extend(fig1_layers)

        # Figure 2: å¤šå°ºåº¦ç‰¹å¾æ¼”è¿›
        print(f"\nğŸ“ˆ Figure 2 - å¤šå°ºåº¦ç‰¹å¾æ¼”è¿›:")
        if len(gdg_final) >= 3:
            fig2_layers = gdg_final[:3]
            print(f"   ğŸ“ å¤šå°ºåº¦GDG: {fig2_layers}")
            # ä¸é‡å¤æ·»åŠ ï¼Œå› ä¸ºå·²ç»åœ¨fig1ä¸­äº†

        # Figure 3: æ³¨æ„åŠ›æœºåˆ¶å¯è§†åŒ–
        print(f"\nğŸ‘ï¸ Figure 3 - æ³¨æ„åŠ›æœºåˆ¶å¯è§†åŒ–:")
        fig3_layers = []

        # ESAæ³¨æ„åŠ›
        esa_layers = patterns['ğŸ‘ï¸ ESAç©ºé—´æ³¨æ„åŠ›']
        if esa_layers:
            fig3_layers.extend(esa_layers[:2])
            print(f"   ğŸ‘ï¸ ESAå±‚: {esa_layers[:2]}")

        # ACAæ³¨æ„åŠ›
        aca_layers = patterns['ğŸ“Š ACAé€šé“æ³¨æ„åŠ›']
        if aca_layers:
            fig3_layers.extend(aca_layers[:2])
            print(f"   ğŸ“Š ACAå±‚: {aca_layers[:2]}")

        # æ®‹å·®æ³¨æ„åŠ›
        res_attn_layers = patterns['ğŸ¯ æ®‹å·®æ³¨æ„åŠ›']
        if res_attn_layers:
            fig3_layers.extend(res_attn_layers)
            print(f"   ğŸ¯ æ®‹å·®æ³¨æ„åŠ›: {res_attn_layers}")

        recommended_layers.extend(fig3_layers)

        # Figure 4: èåˆæœºåˆ¶åˆ†æ
        print(f"\nğŸ”— Figure 4 - èåˆæœºåˆ¶åˆ†æ:")
        fusion_layers = patterns['ğŸ”— èåˆæ¨¡å—']
        if fusion_layers:
            gate_layers = [l for l in fusion_layers if 'gate' in l]
            if gate_layers:
                recommended_layers.extend(gate_layers[:3])
                print(f"   ğŸ”— èåˆé—¨æ§: {gate_layers[:3]}")

        # å»é‡å¹¶ç”Ÿæˆæœ€ç»ˆé…ç½®
        final_layers = list(dict.fromkeys(recommended_layers))  # ä¿æŒé¡ºåºçš„å»é‡

        print(f"\nğŸ’» æœ€ç»ˆGradCAMé…ç½® ({len(final_layers)}ä¸ªå±‚):")
        print("PAPER_TARGET_LAYERS = [")
        for layer in final_layers:
            print(f"    '{layer}',")
        print("]")

        # æµ‹è¯•å±‚çš„æœ‰æ•ˆæ€§
        print(f"\nğŸ§ª æµ‹è¯•å±‚çš„GradCAMé€‚ç”¨æ€§:")
        valid_layers = []
        for layer in final_layers:
            weight_key = f"{layer}.weight"
            if weight_key in state_dict:
                weight_shape = state_dict[weight_key].shape
                if len(weight_shape) == 5:  # 3Då·ç§¯
                    print(f"   âœ… {layer} - 3Då·ç§¯, å½¢çŠ¶: {weight_shape}")
                    valid_layers.append(layer)
                else:
                    print(f"   âš ï¸  {layer} - é3Då·ç§¯, å½¢çŠ¶: {weight_shape}")
            else:
                print(f"   âŒ {layer} - æœªæ‰¾åˆ°æƒé‡")

        # è¾“å‡ºæœ€ç»ˆæœ‰æ•ˆé…ç½®
        print(f"\nğŸ‰ æœ€ç»ˆæœ‰æ•ˆçš„GradCAMå±‚ ({len(valid_layers)}ä¸ª):")
        print("FINAL_GRADCAM_LAYERS = [")
        for layer in valid_layers:
            print(f"    '{layer}',")
        print("]")

        # ä¿å­˜ç»“æœ
        with open('gradcam_layer_config.txt', 'w', encoding='utf-8') as f:
            f.write("GDGMamU_Net GradCAMå±‚é…ç½®\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"æ¨¡å‹æ–‡ä»¶: {model_path}\n")


            f.write("æ¨èçš„è®ºæ–‡å±•ç¤ºå±‚:\n")
            for i, layer in enumerate(valid_layers, 1):
                f.write(f"{i:2d}. '{layer}',\n")

            f.write(f"\nåˆ›æ–°ç»„ä»¶åˆ†ç±»:\n")
            for category, layers in patterns.items():
                if layers:
                    f.write(f"\n{category}:\n")
                    for layer in layers:
                        f.write(f"  - {layer}\n")

        print(f"\nâœ… é…ç½®å·²ä¿å­˜åˆ°: gradcam_layer_config.txt")

        return valid_layers

    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    # ä¿®æ”¹ä¸ºä½ çš„å®é™…æ¨¡å‹è·¯å¾„
    model_path = "../results/best_model_WT0.879_ET0.809_TC0.851_AVG0.846.pth"

    print("ğŸš€ GDGMamU_Net ä¿®å¤ç‰ˆå±‚åˆ†æå·¥å…·")
    print("=" * 80)

    valid_layers = debug_model_layers_fixed(model_path)

    if valid_layers:
        print(f"\nğŸŠ æˆåŠŸ! æ‰¾åˆ° {len(valid_layers)} ä¸ªé€‚åˆè®ºæ–‡å±•ç¤ºçš„GradCAMå±‚")
        print("\nğŸ“‹ ä¸‹ä¸€æ­¥æ“ä½œ:")
        print("1. å¤åˆ¶ä¸Šé¢çš„ FINAL_GRADCAM_LAYERS åˆ°ä½ çš„GradCAMä»£ç ")
        print("2. ä¿®æ”¹ _auto_select_layers æ–¹æ³•è¿”å›è¿™äº›å±‚")
        print("3. è¿è¡ŒGradCAMç”Ÿæˆè®ºæ–‡çº§åˆ«çš„å¯è§†åŒ–")

        print(f"\nğŸ’¡ è®ºæ–‡å±•ç¤ºå»ºè®®:")
        print("â€¢ Figure 1: ä½¿ç”¨GDGå’ŒMambaå±‚å±•ç¤ºæ ¸å¿ƒåˆ›æ–°å¯¹æ¯”")
        print("â€¢ Figure 2: ä½¿ç”¨ä¸åŒå°ºåº¦çš„GDGå±‚å±•ç¤ºå¤šå°ºåº¦å­¦ä¹ ")
        print("â€¢ Figure 3: ä½¿ç”¨æ³¨æ„åŠ›å±‚å±•ç¤ºèšç„¦æœºåˆ¶")
        print("â€¢ Figure 4: ä½¿ç”¨èåˆå±‚å±•ç¤ºè‡ªé€‚åº”èåˆæ•ˆæœ")
    else:
        print("âŒ æœªèƒ½æ‰¾åˆ°æœ‰æ•ˆçš„GradCAMå±‚ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶")