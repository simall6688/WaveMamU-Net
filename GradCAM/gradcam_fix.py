import torch
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
import os
from module.GDGMamU_Net_ESAACA import GDGMamU_Net
from tqdm import tqdm
import h5py
import warnings

warnings.filterwarnings('ignore')


class ImprovedGradCAM3D:
    """æ”¹è¿›çš„3D GradCAMå®ç°ï¼Œç»“åˆæ‰¹æ¬¡ç­–ç•¥å’Œå®Œæ•´åˆ‡ç‰‡ä¿å­˜"""

    def __init__(self, model, target_layer, batch_size=4):
        """
        åˆå§‹åŒ– GradCAM

        :param model: éœ€è¦è¿›è¡Œ GradCAM çš„æ¨¡å‹
        :param target_layer: ç›®æ ‡å±‚çš„åç§°
        :param batch_size: æ‰¹æ¬¡å¤§å°ï¼ˆç”¨äºè§£å†³å½’ä¸€åŒ–å±‚é—®é¢˜ï¼‰
        æ‰¹æ¬¡å¤åˆ¶ç­–ç•¥ï¼šæœ‰æ•ˆè§£å†³äº†å½’ä¸€åŒ–å±‚çš„å…¼å®¹æ€§é—®é¢˜
        """
        self.model = model
        self.target_layer = target_layer
        self.batch_size = batch_size
        self.gradients = None
        self.activations = None
        self.handles = []
        self._register_hooks()

    def _register_hooks(self):
        """æ³¨å†Œå‰å‘å’Œåå‘é’©å­"""

        def forward_hook(module, input, output):
            # ä¿å­˜ç¬¬ä¸€ä¸ªæ ·æœ¬çš„æ¿€æ´»
            self.activations = output[0:1].detach()

        def backward_hook(module, grad_in, grad_out):
            # ä¿å­˜ç¬¬ä¸€ä¸ªæ ·æœ¬çš„æ¢¯åº¦
            if grad_out[0] is not None:
                self.gradients = grad_out[0][0:1].detach()

        # æŸ¥æ‰¾å¹¶æ³¨å†Œé’©å­
        target_found = False
        for name, module in self.model.named_modules():
            if name == self.target_layer:
                fhook = module.register_forward_hook(forward_hook)
                bhook = module.register_backward_hook(backward_hook)
                self.handles.extend([fhook, bhook])
                target_found = True
                break

        if not target_found:
            raise ValueError(f"Layer {self.target_layer} not found in the model.")

    def generate_cam(self, input_tensor, target_class):
        """
        ç”Ÿæˆ CAM

        :param input_tensor: è¾“å…¥å¼ é‡ [1, C, H, W, D]
        :param target_class: ç›®æ ‡ç±»åˆ«
        :return: ç”Ÿæˆçš„ CAM [1, 1, H, W, D]
        """
        self.model.eval()

        # åˆ›å»ºæ‰¹æ¬¡è¾“å…¥
        batch_input = input_tensor.repeat(self.batch_size, 1, 1, 1, 1)
        # æ·»åŠ å¾®å°å™ªå£°é¿å…å®Œå…¨ç›¸åŒ
        noise = torch.randn_like(batch_input) * 0.001
        batch_input = batch_input + noise
        batch_input.requires_grad_(True)

        # å‰å‘ä¼ æ’­
        with torch.set_grad_enabled(True):
            output = self.model(batch_input)

            # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ ·æœ¬çš„è¾“å‡ºè®¡ç®—ç›®æ ‡
            target_output = output[0:1, target_class, :, :, :]
            target = target_output.mean()

            # åå‘ä¼ æ’­
            self.model.zero_grad()
            target.backward()

            # è·å–æ¢¯åº¦å’Œæ¿€æ´»
            if self.gradients is None or self.activations is None:
                raise RuntimeError("Failed to capture gradients or activations")

            # è®¡ç®—æƒé‡ï¼ˆå…¨å±€å¹³å‡æ± åŒ–ï¼‰
            weights = self.gradients.mean(dim=(2, 3, 4), keepdim=True)

            # ç”Ÿæˆ CAM
            cam = (weights * self.activations).sum(dim=1, keepdim=True)
            cam = F.relu(cam)

            # è°ƒæ•´å¤§å°åˆ°è¾“å‡ºå°ºå¯¸
            if cam.shape[2:] != output.shape[2:]:
                cam = F.interpolate(cam, size=output.shape[2:],
                                    mode='trilinear', align_corners=False)

            # å½’ä¸€åŒ– CAM
            cam_min = cam.min()
            cam_max = cam.max()
            if cam_max > cam_min:
                cam = (cam - cam_min) / (cam_max - cam_min)
            else:
                cam = torch.zeros_like(cam)

            return cam

    def cleanup(self):
        """æ¸…ç†é’©å­"""
        for handle in self.handles:
            handle.remove()
        self.handles.clear()
        self.gradients = None
        self.activations = None


def overlay_cam_on_image(original_slice, cam_slice, alpha=0.7):
    """
    å°† Grad-CAM å åŠ åˆ°åŸå§‹å›¾åƒä¸Šï¼ˆä½¿ç”¨æ ‡å‡†çš„jetè‰²å½©æ˜ å°„ï¼‰

    :param original_slice: åŸå§‹å›¾åƒåˆ‡ç‰‡ [H, W]
    :param cam_slice: Grad-CAM åˆ‡ç‰‡ [H, W]
    :param alpha: é€æ˜åº¦
    :return: å åŠ åçš„å›¾åƒ [H, W, 3]
    """
    # å½’ä¸€åŒ–åŸå§‹å›¾åƒåˆ° [0, 1]
    if original_slice.max() > original_slice.min():
        original_norm = (original_slice - original_slice.min()) / (original_slice.max() - original_slice.min())
    else:
        original_norm = np.zeros_like(original_slice)

    # å½’ä¸€åŒ– CAM åˆ° [0, 1]
    if cam_slice.max() > cam_slice.min():
        cam_norm = (cam_slice - cam_slice.min()) / (cam_slice.max() - cam_slice.min())
    else:
        cam_norm = np.zeros_like(cam_slice)

    # ä½¿ç”¨ jet é¢œè‰²æ˜ å°„ï¼ˆè“è‰²åˆ°çº¢è‰²ï¼‰
    cam_color = plt.cm.jet(cam_norm)[:, :, :3]

    # å°†åŸå§‹å›¾åƒè½¬æ¢ä¸º RGB
    original_rgb = np.stack([original_norm] * 3, axis=-1)

    # å åŠ 
    overlay = (1 - alpha) * original_rgb + alpha * cam_color
    overlay = np.clip(overlay, 0, 1)

    return (overlay * 255).astype(np.uint8)


def save_all_slices_cam(cam, original_image, save_path, case_name, class_name,
                        selected_modality=1, alpha=0.5):
    """
    ä¿å­˜æ‰€æœ‰åˆ‡ç‰‡çš„ Grad-CAM å åŠ å›¾åƒ

    :param cam: ç”Ÿæˆçš„ CAM [1, 1, H, W, D]
    :param original_image: åŸå§‹å›¾åƒ [1, 4, H, W, D]
    :param save_path: ä¿å­˜æ ¹è·¯å¾„
    :param case_name: ç—…ä¾‹åç§°
    :param class_name: ç±»åˆ«åç§°
    :param selected_modality: é€‰æ‹©çš„æ¨¡æ€ (0:T1, 1:T1ce, 2:T2, 3:Flair)
    :param alpha: é€æ˜åº¦
    """
    cam_np = cam.cpu().numpy()[0, 0]  # [H, W, D]
    orig_np = original_image.cpu().numpy()[0, selected_modality]  # [H, W, D]

    # åˆ›å»ºä¿å­˜ç›®å½•
    full_save_path = os.path.join(save_path, case_name, class_name)
    os.makedirs(full_save_path, exist_ok=True)

    H, W, D = cam_np.shape
    print(f"  ä¿å­˜ {D} ä¸ªåˆ‡ç‰‡åˆ°: {full_save_path}")

    # ä¿å­˜æ¯ä¸ªåˆ‡ç‰‡
    for d in tqdm(range(D), desc=f'  ä¿å­˜åˆ‡ç‰‡', leave=False):
        orig_slice = orig_np[:, :, d]
        cam_slice = cam_np[:, :, d]

        # åˆ›å»ºå åŠ å›¾åƒ
        overlay = overlay_cam_on_image(orig_slice, cam_slice, alpha=alpha)

        # åˆ›å»ºåŒ…å«åŸå§‹å›¾åƒã€CAMå’Œå åŠ çš„å®Œæ•´å¯è§†åŒ–
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))

        # åŸå§‹å›¾åƒ
        axes[0].imshow(orig_slice, cmap='gray')
        axes[0].set_title(f'Original - Slice {d}')
        axes[0].axis('off')

        # CAMçƒ­å›¾
        im = axes[1].imshow(cam_slice, cmap='jet', vmin=0, vmax=1)
        axes[1].set_title(f'GradCAM - Slice {d}')
        axes[1].axis('off')
        plt.colorbar(im, ax=axes[1], fraction=0.046)

        # å åŠ å›¾
        axes[2].imshow(overlay)
        axes[2].set_title(f'Overlay - Slice {d}')
        axes[2].axis('off')

        # ä¿å­˜
        plt.tight_layout()
        plt.savefig(os.path.join(full_save_path, f'slice_{d:03d}.png'),
                    dpi=150, bbox_inches='tight')
        plt.close()

    # ä¿å­˜æœ€å¤§æŠ•å½±å›¾
    save_projection_views(cam_np, orig_np, full_save_path, alpha)

    print(f"  âœ… å®Œæˆä¿å­˜æ‰€æœ‰åˆ‡ç‰‡")


def save_projection_views(cam_np, orig_np, save_path, alpha=0.5):
    """ä¿å­˜ä¸‰ä¸ªæ–¹å‘çš„æœ€å¤§æŠ•å½±å›¾"""
    projections = {
        'axial': (np.max(cam_np, axis=2), np.max(orig_np, axis=2)),
        'sagittal': (np.max(cam_np, axis=1), np.max(orig_np, axis=1)),
        'coronal': (np.max(cam_np, axis=0), np.max(orig_np, axis=0))
    }

    for view_name, (cam_proj, orig_proj) in projections.items():
        overlay_proj = overlay_cam_on_image(orig_proj, cam_proj, alpha=alpha)

        fig, axes = plt.subplots(1, 3, figsize=(15, 5))

        # åŸå§‹æŠ•å½±
        axes[0].imshow(orig_proj, cmap='gray')
        axes[0].set_title(f'Original - {view_name.capitalize()} Projection')
        axes[0].axis('off')

        # CAMæŠ•å½±
        im = axes[1].imshow(cam_proj, cmap='jet')
        axes[1].set_title(f'GradCAM - {view_name.capitalize()} Projection')
        axes[1].axis('off')
        plt.colorbar(im, ax=axes[1], fraction=0.046)

        # å åŠ æŠ•å½±
        axes[2].imshow(overlay_proj)
        axes[2].set_title(f'Overlay - {view_name.capitalize()} Projection')
        axes[2].axis('off')

        plt.tight_layout()
        plt.savefig(os.path.join(save_path, f'projection_{view_name}.png'),
                    dpi=200, bbox_inches='tight')
        plt.close()


def load_model_safe(model_path, device='cuda'):
    """å®‰å…¨åŠ è½½æ¨¡å‹"""
    model = GDGMamU_Net(in_channels=4, num_classes=4)
    checkpoint = torch.load(model_path, map_location=device,weights_only=False)

    if isinstance(checkpoint, dict):
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
        elif 'state_dict' in checkpoint:
            model.load_state_dict(checkpoint['state_dict'])
        elif 'model' in checkpoint:
            model.load_state_dict(checkpoint['model'])
        else:
            model.load_state_dict(checkpoint)
    else:
        model.load_state_dict(checkpoint)

    model.to(device)
    model.eval()
    return model


def main():
    """ä¸»å‡½æ•° - ç”Ÿæˆæ‰€æœ‰åˆ‡ç‰‡çš„GradCAMå¯è§†åŒ–"""
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ğŸš€ å®Œæ•´åˆ‡ç‰‡GradCAMç”Ÿæˆå·¥å…·")
    print(f"ğŸ“± è®¾å¤‡: {device}")
    print("=" * 80)

    # é…ç½®
    config = {
        'model_path': '../results/best_model_WT0.879_ET0.809_TC0.851_AVG0.846.pth',
        'data_path': "../dataset_output",
        'inference_file': "../dataset_output/inference.txt",
        'save_path': 'gradcam_all_slices',
        'target_size': (160, 160, 128)
    }

    # ç±»åˆ«å®šä¹‰
    class_labels = {
        0: 'Background',
        1: 'ET_EnhancingTumor',
        2: 'TC_TumorCore',
        3: 'WT_WholeTumor'
    }

    # åŠ è½½æ¨¡å‹
    print("åŠ è½½æ¨¡å‹...")
    model = load_model_safe(config['model_path'], device)

    # è¯»å–æ–‡ä»¶åˆ—è¡¨
    with open(config['inference_file'], 'r') as f:
        h5_files = [line.strip() for line in f.readlines() if line.strip()]

    print(f"æ‰¾åˆ° {len(h5_files)} ä¸ªå¾…å¤„ç†æ–‡ä»¶")

    # é€‰æ‹©è¦å¯è§†åŒ–çš„å±‚
    target_layers = [
        'fusion_modules.0.output.2',
        'fusion_modules.1.output.2',
        'fusion_modules.2.output.2',
        'Mamba.mamba.stages.0.blocks.1',
        'Mamba.mamba.stages.1.blocks.1',
        'Mamba.mamba.stages.0.blocks.0.dwconv1.depth_conv',
        'GDG2.mish',
        'GDG1.mish'
    ]

    # é€‰æ‹©è¦ç”Ÿæˆçš„ç±»åˆ«
    classes_to_generate = [1, 2, 3]  # ET, TC, WT

    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    for idx, h5_file in enumerate(h5_files[:3]):  # é™åˆ¶å¤„ç†å‰3ä¸ªæ–‡ä»¶
        h5_path = os.path.join(config['data_path'], 'dataset', h5_file)

        if not os.path.exists(h5_path):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {h5_path}")
            continue

        print(f"\nå¤„ç†æ–‡ä»¶ {idx + 1}/{min(3, len(h5_files))}: {h5_file}")

        # åŠ è½½æ•°æ®
        with h5py.File(h5_path, 'r') as f:
            image = torch.from_numpy(f['image'][:]).float().unsqueeze(0)

        # è°ƒæ•´å¤§å°
        if image.shape[2:] != config['target_size']:
            image = F.interpolate(image, size=config['target_size'],
                                  mode='trilinear', align_corners=False)

        image = image.to(device)
        case_name = os.path.splitext(os.path.basename(h5_file))[0]

        # å¯¹æ¯ä¸ªç›®æ ‡å±‚ç”ŸæˆGradCAM
        for target_layer in target_layers:
            print(f"\nç›®æ ‡å±‚: {target_layer}")

            # åˆå§‹åŒ–GradCAM
            gradcam = ImprovedGradCAM3D(model, target_layer, batch_size=4)

            # å¯¹æ¯ä¸ªç±»åˆ«ç”ŸæˆCAM
            for target_class in classes_to_generate:
                class_name = class_labels[target_class]
                print(f"  ç”Ÿæˆç±»åˆ« {target_class} ({class_name}) çš„GradCAM...")

                try:
                    # ç”ŸæˆCAM
                    cam = gradcam.generate_cam(image, target_class)

                    # ä¿å­˜æ‰€æœ‰åˆ‡ç‰‡
                    save_all_slices_cam(
                        cam, image,
                        os.path.join(config['save_path'], target_layer.replace('.', '_')),
                        case_name, class_name,
                        selected_modality=1,  # ä½¿ç”¨T1ce
                        alpha=0.5
                    )

                except Exception as e:
                    print(f"  âŒ ç”Ÿæˆå¤±è´¥: {e}")
                    continue

            # æ¸…ç†é’©å­
            gradcam.cleanup()

    print(f"\nğŸ‰ å®Œæˆï¼æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {config['save_path']}")


if __name__ == '__main__':
    main()